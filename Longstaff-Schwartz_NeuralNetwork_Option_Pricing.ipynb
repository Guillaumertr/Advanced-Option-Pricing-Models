{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longstaff-Schwartz Method with Neural Networks\n",
    "\n",
    "This notebook implements the **Longstaff-Schwartz algorithm** using neural networks to approximate the continuation value, enabling the pricing of high-dimensional American options.\n",
    "\n",
    "This is an extension of the classical Least-Squares Monte Carlo (LSM) method using a deep learning model to better capture non-linear relationships in the state space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset\n",
    "\n",
    "This class simulates asset price trajectories under the **risk-neutral measure**, assuming a geometric Brownian motion (GBM) process. It supports a multi-dimensional setting with `d` assets and runs on GPU if available.\n",
    "\n",
    "### Attributes:\n",
    "- `s0` : Initial asset price (scalar or vector of size `d`).\n",
    "- `r` : Risk-free interest rate.\n",
    "- `div` : Continuous dividend rate.\n",
    "- `sigma` : Volatility (can be a scalar or vector of shape `(d,)`).\n",
    "- `T` : Time to maturity.\n",
    "- `N` : Number of time steps.\n",
    "- `M` : Number of Monte Carlo paths.\n",
    "- `d` : Number of assets.\n",
    "- `device` : `\"cpu\"` or `\"cuda\"` (or `\"mps\"` on Apple Silicon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Asset:\n",
    "    def __init__(self, s0, r, div, sigma, T = 3, N = 9, M = 8192, d = 5, device = \"cpu\"):\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.d = d\n",
    "        self.T = T\n",
    "        self.delta = T / N\n",
    "        self.s0 = s0\n",
    "        self.r = r\n",
    "        self.div = div\n",
    "        self.sigma = sigma\n",
    "        self.device = device\n",
    "\n",
    "    def brownian_paths(self, noise):\n",
    "        dB = torch.zeros((noise.shape), device = self.device)\n",
    "        dB[1:] = torch.sqrt(torch.tensor(self.delta, device = self.device)) * noise[1:]\n",
    "        B = torch.cumsum(dB, axis = 0)\n",
    "\n",
    "        return B\n",
    "\n",
    "    def asset_paths(self, scenario_size = None):\n",
    "        M = scenario_size or self.M\n",
    "\n",
    "        noise = torch.randn(size = (self.N + 1, M, self.d), device = self.device)\n",
    "        B = self.brownian_paths(noise)\n",
    "        tn = (torch.arange(self.N + 1, device = self.device) * self.delta)[:, None, None]\n",
    "\n",
    "        S = self.s0 * torch.exp((self.r - self.div - 0.5 * self.sigma ** 2) * tn + self.sigma * B)\n",
    "\n",
    "        return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Option Classes\n",
    "\n",
    "These classes define the **discounted payoff** for American options, based on the **maximum over `d` assets**. They support both put and call payoffs.\n",
    "\n",
    "Each option:\n",
    "- Takes an `Asset` instance.\n",
    "- Defines the strike `K`.\n",
    "- Implements:\n",
    "  - `payoff(X, n)` to compute discounted payoff,\n",
    "\n",
    "**Payoff formulas :**\n",
    "- Put : $\\max(K - \\max_i S^{(i)}, 0)$  \n",
    "- Call : $\\max(\\max_i S^{(i)} - K, 0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPutOption():\n",
    "    def __init__(self, asset, K, device = \"cpu\"):\n",
    "        self.asset = asset\n",
    "        self.K = K\n",
    "        self.device = device\n",
    "\n",
    "    def payoff(self, X, n = None, discounted = True):\n",
    "        max_value = torch.max(X, axis = -1)[0]\n",
    "        payoff_value = torch.relu(self.K - max_value)\n",
    "        if discounted :\n",
    "            tn = (torch.arange(X.shape[0], device = self.device) * self.asset.delta)[:, None]\n",
    "            payoff_value = torch.exp(- self.asset.r * tn) * payoff_value\n",
    "\n",
    "        return payoff_value[n] if n is not None else payoff_value\n",
    "    \n",
    "class MaxCallOption():\n",
    "    def __init__(self, asset, K, device = \"cpu\"):\n",
    "        self.asset = asset\n",
    "        self.K = K\n",
    "        self.device = device\n",
    "\n",
    "    def payoff(self, X, n = None, discounted = True):\n",
    "        max_value = torch.max(X, axis = -1)[0]\n",
    "        payoff_value = torch.relu(max_value - self.K)\n",
    "        if discounted :\n",
    "            tn = (torch.arange(X.shape[0], device = self.device) * self.asset.delta)[:, None]\n",
    "            payoff_value = torch.exp(- self.asset.r * tn) * payoff_value\n",
    "\n",
    "        return payoff_value[n] if n is not None else payoff_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model\n",
    "\n",
    "A generic feedforward network with BatchNorm and ReLU activations used to approximate the continuation value at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, layer_sizes, output_size):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.Linear(input_size, layer_sizes[0]))\n",
    "        layers.append(nn.BatchNorm1d(layer_sizes[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.BatchNorm1d(out_size))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(layer_sizes[-1], output_size))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LongstaffSchwartzPricerNN\n",
    "\n",
    "This class implements the **Longstaff-Schwartz method using neural networks** to estimate the continuation value at each time step.\n",
    "\n",
    "Instead of a polynomial basis, this implementation uses a fully connected neural network to learn the mapping from the state (e.g., asset prices) to continuation values, making it more flexible and scalable for high-dimensional problems.\n",
    "\n",
    "### Main methods:\n",
    "\n",
    "- `initialize_model()` : Creates a fresh feedforward neural network (with user-defined architecture) for a given time step.\n",
    "- `copy_model_weights(model_from, model_to)` : Copies weights from one neural network to another, enabling warm-start training across time steps.\n",
    "- `train()` : Trains one neural network per time step in **backward order** using Monte Carlo paths:\n",
    "  - For each date, the network is trained to approximate the continuation value by minimizing the squared error with respect to the future payoff.\n",
    "  - Training is performed in batches using stochastic gradient descent (via the Adam optimizer).\n",
    "- `compute_exercise_policy(X)` : Given trained models and new asset paths, this method applies the **optimal exercise policy** by comparing the continuation value to the immediate payoff.\n",
    "- `get_price(sample_size)` : \n",
    "  - Simulates a new set of paths.\n",
    "  - Applies the trained models to determine optimal stopping decisions.\n",
    "  - Returns the estimated price and a confidence interval.\n",
    "\n",
    "## Pricing Logic\n",
    "\n",
    "### `train()` :\n",
    "- For each time step `n = N-1, ..., 0`:\n",
    "  - Copy the weights from the future model (`n+1`) to initialize the model at time `n`.\n",
    "  - Regress the future payoff `payoff_opt` on the state `X[n]` using a neural network.\n",
    "  - Update weights by minimizing the squared error over batches.\n",
    "  - Once trained, use the model to determine whether early exercise is optimal:\n",
    "  - Update `payoff_opt` accordingly.\n",
    "\n",
    "### `compute_exercise_policy(X)` :\n",
    "- Applies the trained policy to a new set of asset paths `X`.\n",
    "- At each time step, determines whether to exercise early based on the learned continuation model.\n",
    "- Returns the optimal payoff per path.\n",
    "\n",
    "### `get_price(sample_size)` :\n",
    "- Simulates a new Monte Carlo sample of asset trajectories.\n",
    "- Applies the exercise policy.\n",
    "- Computes the **mean payoff** as the estimated option price.\n",
    "- Also returns a **confidence interval** based on the Central Limit Theorem:\n",
    "  \\[\n",
    "  \\text{CI} = \\bar{V} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{N}}\n",
    "  \\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongstaffSchwartzPricerNN:\n",
    "    def __init__(self, asset, option, layers, device = \"cpu\"):\n",
    "        \"\"\"\n",
    "        Initializes a Longstaff-Schwartz pricer using a neural network model.\n",
    "\n",
    "        Parameters:\n",
    "        - asset : object representing the underlying asset.\n",
    "        - option : object representing the option to be priced.\n",
    "        - layers : list representing the layer sizes of the neural network.\n",
    "        - device : device for execution (default is \"cpu\").\n",
    "        \"\"\"\n",
    "        self.asset = asset\n",
    "        self.option = option\n",
    "        self.device = device\n",
    "        self.layers = layers\n",
    "\n",
    "        self.option.device = device\n",
    "        self.asset.device = device\n",
    "\n",
    "        self.thetas = None\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"\n",
    "        Initializes a neural network model with the appropriate input dimension.\n",
    "\n",
    "        Returns:\n",
    "        - Network : a neural network model.\n",
    "        \"\"\"\n",
    "        input_dim = self.asset.d\n",
    "        return Network(input_dim, self.layers, 1).to(self.device)\n",
    "\n",
    "    def copy_model_weights(self, model_from, model_to):\n",
    "        \"\"\"\n",
    "        Copies weights from one model to another.\n",
    "\n",
    "        Parameters:\n",
    "        - model_from : source model.\n",
    "        - model_to : target model.\n",
    "        \"\"\"\n",
    "        model_to.load_state_dict(model_from.state_dict())\n",
    "\n",
    "    def train(self, n_epochs = 20, batch_size = 8192, learning_rate = 1e-3):\n",
    "        \"\"\"\n",
    "        Trains the neural network models for each time step.\n",
    "\n",
    "        Parameters:\n",
    "        - n_epochs : number of training epochs.\n",
    "        - batch_size : size of the batch for weight updates.\n",
    "        - learning_rate : learning rate for the optimizer.\n",
    "        \n",
    "        Returns:\n",
    "        - payoff_opt : estimated option value at each step.\n",
    "        \"\"\"\n",
    "        X = self.asset.asset_paths()\n",
    "        payoff = self.option.payoff(X)\n",
    "        payoff_opt = payoff[-1].clone()\n",
    "\n",
    "        self.thetas = [self.initialize_model() for _ in range(self.asset.N)]\n",
    "        optimizers = [torch.optim.Adam(self.thetas[n].parameters(), lr = learning_rate) for n in range(self.asset.N)]\n",
    "\n",
    "        for n in reversed(range(self.asset.N)):\n",
    "            samples_size = X.shape[1]\n",
    "            num_batches = samples_size // batch_size\n",
    "\n",
    "            # Copy the n+1 model weight to the n model\n",
    "            if n < self.asset.N - 1:\n",
    "                self.copy_model_weights(self.thetas[n + 1], self.thetas[n])\n",
    "\n",
    "            for _ in tqdm(range(n_epochs), desc = f\"Training at timestep {n}\"):\n",
    "                indexes = torch.randperm(samples_size, device = self.device)\n",
    "                for k in range(num_batches):\n",
    "                    idx = indexes[k * batch_size:(k + 1) * batch_size]\n",
    "                    loss = ((payoff_opt[idx] - self.thetas[n](X[n, idx]))**2).mean()\n",
    "                    optimizers[n].zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizers[n].step()\n",
    "\n",
    "            exercise_now = payoff[n] >= self.thetas[n](X[n])\n",
    "            payoff_opt[exercise_now] = payoff[n, exercise_now].clone()\n",
    "\n",
    "    def compute_exercise_policy(self, X):\n",
    "        \"\"\"\n",
    "        Computes the optimal exercise policy using the trained networks, starting from the last time step.\n",
    "\n",
    "        Parameters:\n",
    "        - X : matrix of asset paths for each Monte Carlo simulation.\n",
    "\n",
    "        Returns:\n",
    "        - payoff_opt : optimal payoffs\n",
    "        \"\"\"\n",
    "        payoff = self.option.payoff(X)\n",
    "        payoff_opt = payoff[-1]\n",
    "\n",
    "        for n in range(X.shape[0] - 2, -1, -1):\n",
    "            exercise_now = payoff[n] >= self.thetas[n](X[n])\n",
    "            payoff_opt[exercise_now] = payoff[n, exercise_now].clone()\n",
    "\n",
    "        return payoff_opt\n",
    "\n",
    "    def get_price(self, sample_size, confidence_level: float = 0.95):\n",
    "        \"\"\"\n",
    "        Computes the estimated option price and its confidence interval.\n",
    "\n",
    "        Parameters:\n",
    "        - sample_size : number of samples for the estimation.\n",
    "        - confidence_level : confidence level for the interval (default is 95%).\n",
    "\n",
    "        Prints:\n",
    "        - Estimated option price and its confidence interval.\n",
    "        \"\"\"\n",
    "        print(f\"\\nPricing the option via LongStaffSchwartz NeuralNetwork...\")\n",
    "\n",
    "        X = self.asset.asset_paths(scenario_size = sample_size)\n",
    "        payoff_opt = self.compute_exercise_policy(X).cpu().numpy()\n",
    "        \n",
    "        mean_payoff = payoff_opt.mean()\n",
    "        variance = np.var(payoff_opt, ddof=1)\n",
    "\n",
    "        alpha = 1 - confidence_level\n",
    "        quantile = stats.norm.ppf(1 - alpha / 2)\n",
    "\n",
    "        ci_lower = mean_payoff - quantile * np.sqrt(variance / sample_size)\n",
    "        ci_upper = mean_payoff + quantile * np.sqrt(variance / sample_size)\n",
    "\n",
    "        print(f\"\\n=== Option Pricing Results ===\")\n",
    "        print(f\"Estimated Price     : {mean_payoff:.6f}\")\n",
    "        print(f\"Confidence Level    : {confidence_level*100:.1f}%\")\n",
    "        print(f\"Confidence Interval : [{ci_lower:.6f}, {ci_upper:.6f}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of the Neural Network Approach\n",
    "\n",
    "A key benefit of using neural networks beyond enabling pricing in higher-dimensional settings is that we do not need to manually specify a basis of functions.\n",
    "Unlike traditional Longstaff-Schwartz regression, where the choice of basis (e.g., polynomials) can significantly impact accuracy, the neural network automatically learns an appropriate nonlinear representation from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training at timestep 8: 100%|██████████| 100/100 [00:05<00:00, 17.93it/s]\n",
      "Training at timestep 7: 100%|██████████| 100/100 [00:05<00:00, 18.07it/s]\n",
      "Training at timestep 6: 100%|██████████| 100/100 [00:05<00:00, 18.03it/s]\n",
      "Training at timestep 5: 100%|██████████| 100/100 [00:05<00:00, 17.93it/s]\n",
      "Training at timestep 4: 100%|██████████| 100/100 [00:05<00:00, 17.87it/s]\n",
      "Training at timestep 3: 100%|██████████| 100/100 [00:05<00:00, 18.03it/s]\n",
      "Training at timestep 2: 100%|██████████| 100/100 [00:05<00:00, 17.82it/s]\n",
      "Training at timestep 1: 100%|██████████| 100/100 [00:05<00:00, 17.92it/s]\n",
      "Training at timestep 0: 100%|██████████| 100/100 [00:05<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pricing the option via LongStaffSchwartz NeuralNetwork...\n",
      "\n",
      "=== Option Pricing Results ===\n",
      "Estimated Price     : 18.604731\n",
      "Confidence Level    : 95.0%\n",
      "Confidence Interval : [18.585340, 18.624121]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asset = Asset(s0 = 100,\n",
    "              r = 0.05,\n",
    "              div = 0.1,\n",
    "              sigma = 0.2,\n",
    "              T = 3,\n",
    "              N = 9,\n",
    "              M = 200_000,\n",
    "              d = 3,\n",
    "              device = \"mps\")\n",
    "\n",
    "option = MaxCallOption(asset, \n",
    "                    K = 100, \n",
    "                    device = \"mps\")\n",
    "\n",
    "pricer = LongstaffSchwartzPricerNN(asset, \n",
    "                                   option, \n",
    "                                   layers = [8, 8], \n",
    "                                   device = \"mps\")\n",
    "pricer.train(n_epochs = 100)\n",
    "pricer.get_price(sample_size = 2_960_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training at timestep 8: 100%|██████████| 100/100 [00:05<00:00, 17.52it/s]\n",
      "Training at timestep 7: 100%|██████████| 100/100 [00:05<00:00, 17.97it/s]\n",
      "Training at timestep 6: 100%|██████████| 100/100 [00:05<00:00, 17.62it/s]\n",
      "Training at timestep 5: 100%|██████████| 100/100 [00:05<00:00, 17.85it/s]\n",
      "Training at timestep 4: 100%|██████████| 100/100 [00:05<00:00, 17.79it/s]\n",
      "Training at timestep 3: 100%|██████████| 100/100 [00:05<00:00, 17.86it/s]\n",
      "Training at timestep 2: 100%|██████████| 100/100 [00:05<00:00, 17.54it/s]\n",
      "Training at timestep 1: 100%|██████████| 100/100 [00:05<00:00, 17.75it/s]\n",
      "Training at timestep 0: 100%|██████████| 100/100 [00:05<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pricing the option via LongStaffSchwartz NeuralNetwork...\n",
      "\n",
      "=== Option Pricing Results ===\n",
      "Estimated Price     : 5.755755\n",
      "Confidence Level    : 95.0%\n",
      "Confidence Interval : [5.746714, 5.764796]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "option = MaxPutOption(asset, \n",
    "                    K = 100, \n",
    "                    device = \"mps\")\n",
    "\n",
    "pricer = LongstaffSchwartzPricerNN(asset, \n",
    "                                   option, \n",
    "                                   layers = [8, 8], \n",
    "                                   device = \"mps\")\n",
    "pricer.train(n_epochs = 100)\n",
    "pricer.get_price(sample_size = 2_960_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
